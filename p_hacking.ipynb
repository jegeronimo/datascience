{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from datascience import *\n",
    "\n",
    "import numpy as np\n",
    "from scipy import stats, special\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import itertools\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_VARIABLES = make_array(\"Size\", \"Shape\", \"Weight\", \"Height\", \"Width\", \"Density\", \"Length\", \"Time\",\n",
    "                               \"Speed\", \"Acceleration\", \"Reflectivity\", \"Emissivity\", \"Strength\", \"Age\",\n",
    "                               \"Bounce\", \"Price\", \"Rarity\", \"X\", \"Y\", \"Z\", \"Number\", \"Cost\", \"Absorptivity\",\n",
    "                                \"Magnetism\", \"Conductance\", \"Impedance\", \"Resistance\", \"Volume\", \"Boiling\", \"Melting\", \n",
    "                                \"Freezing\")\n",
    "\n",
    "def generate_data(n, r, sample_size):\n",
    "    np.random.seed(8)\n",
    "    # build the table\n",
    "    table = Table()\n",
    "    variable_names = np.random.choice(POSSIBLE_VARIABLES, n, replace=False)\n",
    "    for i in np.arange(n-1):\n",
    "        mean = stats.norm.rvs(250, 300)\n",
    "        std = abs(stats.norm.rvs(50, 20))\n",
    "        values = stats.norm.rvs(mean, std, sample_size)\n",
    "        table = table.with_column(variable_names.item(i), values)\n",
    "    signal_column = np.random.choice(n-1)\n",
    "    signal = table.column(signal_column)\n",
    "    mean = stats.norm.rvs(250, 300)\n",
    "    std = abs(stats.norm.rvs(50, 20))\n",
    "    z = (signal - np.mean(signal)) / np.std(signal)\n",
    "    z_rescaled = z * std + mean\n",
    "    noise = stats.norm.rvs(mean, std, sample_size)\n",
    "    signal_and_noise = r*z_rescaled + (1-abs(r))*noise\n",
    "    table = table.with_column(variable_names.item(n-1), signal_and_noise)\n",
    "    # print(\"Signal is \" + str(variable_names.item(signal_column)))\n",
    "    result_column = variable_names.item(n-1)\n",
    "    # print(\"Result is \" + str(result_column))\n",
    "    return table.select(np.sort(table.labels)), make_array(variable_names.item(signal_column), variable_names.item(n-1))\n",
    "    \n",
    "\n",
    "def correlation(x, y):\n",
    "    x_z = (x-np.mean(x))/np.std(x)\n",
    "    y_z = (y-np.mean(y))/np.std(y)\n",
    "    \n",
    "    return np.mean(x_z*y_z)\n",
    "\n",
    "def bootstrap_correlations(tbl, x_col, y_col):\n",
    "    tbl_select = tbl.select(x_col, y_col)\n",
    "    correlations = make_array()\n",
    "    for i in np.arange(1000):\n",
    "        resample = tbl_select.sample()\n",
    "        corr = correlation(resample.column(0), resample.column(1))\n",
    "        correlations = np.append(correlations, corr)\n",
    "    return correlations\n",
    "\n",
    "def p_value(tbl, x_col, y_col, p):\n",
    "    correlations = bootstrap_correlations(tbl, x_col, y_col)\n",
    "    upper = percentile((1-p/2) * 100, correlations)\n",
    "    lower = percentile(p/2 * 100, correlations)\n",
    "    if lower <= 0 and upper >= 0:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def calculate_stats(data, p=0.05):\n",
    "    correlations = Table(make_array(\"Variable X\", \"Variable Y\", \"Corr\", \"Passes Hypothesis Test\"))\n",
    "    for i in np.arange(data.num_columns):\n",
    "        for j in np.arange(data.num_columns):\n",
    "            if j < i:\n",
    "                corr = correlation(data.column(i), data.column(j))\n",
    "                correlations = correlations.append(make_array(i, j, corr, p_value(data, i, j, p)))\n",
    "    return correlations.sort(\"Passes Hypothesis Test\", descending=True)\n",
    "\n",
    "def perform_test(num_variables=7, p_value=0.05, true_corr=.5):\n",
    "    print(\"Generating Data...\")\n",
    "    data, true_pair = generate_data(num_variables, true_corr)\n",
    "    print(\"Calculating Correlations and Significance...\")\n",
    "    stats_table = calculate_stats(data, p_value)\n",
    "    print(\"Bootstrapping Finished...\")\n",
    "    passed_tests = stats_table.where(3, 1)\n",
    "    print(f\"Out of {special.comb(num_variables, 2)} pairs of correlations, {passed_tests.num_rows} were significant\")\n",
    "    found = False\n",
    "    for i in np.arange(passed_tests.num_rows):\n",
    "        col_x = data.labels[int(passed_tests.column(0).item(i))]\n",
    "        col_y = data.labels[int(passed_tests.column(1).item(i))]\n",
    "        data.scatter(col_x, col_y)\n",
    "        if np.all(np.sort(make_array(col_x, col_y)) == np.sort(true_pair)):\n",
    "            found = True\n",
    "    if found:\n",
    "        print(f\"The true signal pair {true_pair} was found!\")\n",
    "    else:\n",
    "        print(f\"The true signal pair {true_pair} was not found :(\")\n",
    "    \n",
    "    num_found = passed_tests.num_rows - int(found)\n",
    "    # This calculation is actually wrong! A binomial model is an underapproximation since correlations are not independent\n",
    "    # print(f\"With a P value of {p_value}, the probability that {num_found} or more correlations are inccorectely found to be significant \\n under the null hypothesis is {1-stats.binom.cdf(num_found-1, stats_table.num_rows-1, p_value)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def perform_test(num_variables=7, p_value=0.05, true_corr=.5, sample_size_log = 2, out_found = False):\n",
    "    print(\"Generating Data...\")\n",
    "    data, true_pair = generate_data(num_variables, true_corr, 10**sample_size_log)\n",
    "    print(\"Calculating Correlations and Significance...\")\n",
    "    stats_table = calculate_stats(data, p_value)\n",
    "    print(\"Bootstrapping Finished...\")\n",
    "    passed_tests = stats_table.where(3, 1)\n",
    "    print(f\"Out of {special.comb(num_variables, 2)} pairs of correlations, {passed_tests.num_rows} were significant\")\n",
    "    found = False\n",
    "    all_pairs = []\n",
    "    '''\n",
    "    fig_x = 15\n",
    "    fig_y = 15\n",
    "    figsize = (fig_x, fig_y)\n",
    "    if stats_table.num_rows % 3 == 0:\n",
    "        fig, axes = plt.subplots(stats_table.num_rows//3, 3, figsize=figsize)\n",
    "    else:\n",
    "        fig, axes = plt.subplots(stats_table.num_rows//3 + 1, 3, figsize=figsize)\n",
    "        for i in np.arange(stats_table.num_rows, (stats_table.num_rows //3 + 1)*3):\n",
    "            axes[i//3, i%3].axis('off')\n",
    "    fig.tight_layout(pad=3)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    for i in np.arange(stats_table.num_rows):\n",
    "        col_x = data.labels[int(stats_table.column(0).item(i))]\n",
    "        col_y = data.labels[int(stats_table.column(1).item(i))]\n",
    "        all_pairs.append(np.sort(make_array(col_x, col_y)))\n",
    "        \n",
    "        axes[i//3, i%3].scatter(data.column(col_x), data.column(col_y))\n",
    "        axes[i//3, i%3].set_xlabel(col_x)\n",
    "        axes[i//3, i%3].set_ylabel(col_y)\n",
    "    '''\n",
    "    sns.pairplot(data.to_df())\n",
    "    \n",
    "    \n",
    "    found = False\n",
    "    for i in np.arange(passed_tests.num_rows):\n",
    "        col_x = data.labels[int(passed_tests.column(0).item(i))]\n",
    "        col_y = data.labels[int(passed_tests.column(1).item(i))]\n",
    "        if np.all(np.sort(make_array(col_x, col_y)) == np.sort(true_pair)):\n",
    "            found = True\n",
    "    if out_found:\n",
    "        if found:\n",
    "            print(f\"The true signal pair {true_pair} was significant!\")\n",
    "        else:\n",
    "            print(f\"The true signal pair {true_pair} was not significant! :(\")\n",
    "            \n",
    "    def guesser(x, y):\n",
    "        data.scatter(x, y)\n",
    "        sig = False\n",
    "        for i in np.arange(stats_table.num_rows):\n",
    "            col_x = data.labels[int(stats_table.column(0).item(i))]\n",
    "            col_y = data.labels[int(stats_table.column(1).item(i))]\n",
    "            if np.all(np.sort(make_array(col_x, col_y)) == np.sort(make_array(x, y))):\n",
    "                sig = True\n",
    "        if sig:\n",
    "            print(\"Result is Significant\")\n",
    "        else:\n",
    "            print('Result is not Significant')\n",
    "        if np.all(np.sort(make_array(x, y)) == np.sort(true_pair)):\n",
    "            print(\"Correct Guess! This was the true association\")\n",
    "        else:\n",
    "            print(\"Try Again :( This was not the true association\")\n",
    "    \n",
    "    \n",
    "    return lambda : interact(guesser, x= list(data.labels), y = list(data.labels))\n",
    "    \n",
    "    #num_found = passed_tests.num_rows - int(found)\n",
    "    # This calculation is actually wrong! A binomial model is an underapproximation since correlations are not independent\n",
    "    # print(f\"With a P value of {p_value}, the probability that {num_found} or more correlations are inccorectely found to be significant \\n under the null hypothesis is {1-stats.binom.cdf(num_found-1, stats_table.num_rows-1, p_value)}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Key Terms / Review\n",
    "Let's review some key terms first!\n",
    "\n",
    "An association is a predictable relationship between two variables. A specific kind of association we will be looking at is a linear association, otherwise known as a correlation. A correlation means as one variable increases, the other variable either increases as well (positive correlation) or decreases (negative correlation).\n",
    "\n",
    "Associations can be more or less meaningful. There are a number of ways to test how meaningful-- or significant-- a correlation is.\n",
    "\n",
    "A p-value is the probability of seeing results like you got or more extreme, IF your hypothesis were false. So the smaller the p-value, the less likely your pattern is the result of chance, and the more likely it is to be a result of a true association. Scientists choose a cut-off of probability that they agree to consider \"statistically significant,\" typically .05. This means that, on average, 5% of all findings that are \"statistically significant at .05\" are actually due to chance, and not a true association. The lower the p-value, the less likely it is the apparent association is due to chance, and the more likely it is to replicate.\n",
    "\n",
    "Scientists typically set a rigid cutoff to determine when a correlation will be considered statistically significant or not significant-- this is called a p value cutoff or alpha. A p value cutoff tells us the probability that we will call a non significant correlation significant. For example, if we test 20 different correlations that are not significant, if we use the common p value cut off of 5%, we would expect one of them, on average to be classified as significant incorrectly (5% = 1 in 20). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tam is running a simple study where she measures certain variables of a set of marbles, looking for associations among the variables. As her first experiment, she collects the following data. Run the code cell below to inspect the results of her study.\n",
    "\n",
    "Tam knows that in each study, only two of the variables are actually correlated! For each study, the marble factory sends Tam a fresh batch of marbles. When ordering the marbles from the factory, Tam can control the true correlation in the associated variables and the number of marbles. All the other variables are generated randomly. \n",
    "\n",
    "The cell will tell you, 1: how many pairs of correlations were statistically significant, and 2: display graphs of the associations between all variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesser = perform_test(num_variables=4, p_value=0.05, true_corr=0.45, sample_size_log=1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Looking at the graphs, can you tell which correlation is the true correlation? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** None of the correlations were statistically significant. Besides increasing the sample size, what else can Tam do to improve statistical significance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesser = perform_test(num_variables=4, p_value=0.05, true_corr=0.45, sample_size_log=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** With the new sample size, two results are significant. Interact with the cell below to identify your guess for pair of variables were actually correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesser();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsure of her results, Tam observed more variables in her next experiment.\n",
    "\n",
    "**Question 4:** As Tam observes the correlations among a larger set of variables, will the number of statisically significant results increase, decrease or stay the same, and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guesser = perform_test(num_variables=8, p_value=0.05, true_corr=0.45, sample_size_log=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** Try and find the true correlation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesser();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** How can Tam reduce the number of false positives while still investigating the same, larger, number of variables?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "guesser = perform_test(num_variables=10, p_value=0.05, true_corr=0.75, sample_size_log=2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** In the previous example you should be able to identify the true correlation more easily than before, although there are more comparisons. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guesser();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:** How would you describe the signal and noise in this study?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9:** In creating this module, Yanay tried to approximate the probability of a certain number of incorrect correlations in this experiment using a binomial model. Is this correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 10:** What is a real life example of an experiment like the one we simulate here, observing lots of variables and looking for associations??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11:** Tam originally tested her main hypothesis, which was about a specific correlation between two variables. Why is there a lower chance of getting a false positive when testing one specific hypothesis, than when looking at a whole lot of possible correlations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12:** The factory was contacted by a few other data scientists who performed similar studies to Tam's. How would this affect the number of false positives? How does this relate to public data sets analyzed by many research groups, as is very common in data science?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
